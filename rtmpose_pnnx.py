import os
import numpy as np
import tempfile, zipfile
import torch
import torch.nn as nn
import torch.nn.functional as F
try:
    import torchvision
except:
    pass

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()

        self.convbn2d_0 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=3, kernel_size=(3,3), out_channels=16, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.stem_0_activate = nn.SiLU()
        self.convbn2d_1 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=16, kernel_size=(3,3), out_channels=16, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stem_1_activate = nn.SiLU()
        self.convbn2d_2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=16, kernel_size=(3,3), out_channels=32, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stem_2_activate = nn.SiLU()
        self.convbn2d_3 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.stage1_0_activate = nn.SiLU()
        self.convbn2d_4 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=32, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage1_1_short_conv_activate = nn.SiLU()
        self.convbn2d_5 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=32, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage1_1_main_conv_activate = nn.SiLU()
        self.convbn2d_6 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(3,3), out_channels=32, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stage1_1_blocks_0_conv1_activate = nn.SiLU()
        self.convbn2d_7 = nn.Conv2d(bias=True, dilation=(1,1), groups=32, in_channels=32, kernel_size=(5,5), out_channels=32, padding=(2,2), padding_mode='zeros', stride=(1,1))
        self.stage1_1_blocks_0_conv2_depthwise_conv_activate = nn.SiLU()
        self.convbn2d_8 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=32, kernel_size=(1,1), out_channels=32, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage1_1_blocks_0_conv2_pointwise_conv_activate = nn.SiLU()
        self.stage1_1_attention_global_avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))
        self.stage1_1_attention_fc = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage1_1_attention_act = nn.Hardsigmoid()
        self.convbn2d_9 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage1_1_final_conv_activate = nn.SiLU()
        self.convbn2d_10 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.stage2_0_activate = nn.SiLU()
        self.convbn2d_11 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage2_1_short_conv_activate = nn.SiLU()
        self.convbn2d_12 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage2_1_main_conv_activate = nn.SiLU()
        self.convbn2d_13 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stage2_1_blocks_0_conv1_activate = nn.SiLU()
        self.convbn2d_14 = nn.Conv2d(bias=True, dilation=(1,1), groups=64, in_channels=64, kernel_size=(5,5), out_channels=64, padding=(2,2), padding_mode='zeros', stride=(1,1))
        self.stage2_1_blocks_0_conv2_depthwise_conv_activate = nn.SiLU()
        self.convbn2d_15 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage2_1_blocks_0_conv2_pointwise_conv_activate = nn.SiLU()
        self.convbn2d_16 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stage2_1_blocks_1_conv1_activate = nn.SiLU()
        self.convbn2d_17 = nn.Conv2d(bias=True, dilation=(1,1), groups=64, in_channels=64, kernel_size=(5,5), out_channels=64, padding=(2,2), padding_mode='zeros', stride=(1,1))
        self.stage2_1_blocks_1_conv2_depthwise_conv_activate = nn.SiLU()
        self.convbn2d_18 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=64, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage2_1_blocks_1_conv2_pointwise_conv_activate = nn.SiLU()
        self.stage2_1_attention_global_avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))
        self.stage2_1_attention_fc = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage2_1_attention_act = nn.Hardsigmoid()
        self.convbn2d_19 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage2_1_final_conv_activate = nn.SiLU()
        self.convbn2d_20 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=256, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.stage3_0_activate = nn.SiLU()
        self.convbn2d_21 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage3_1_short_conv_activate = nn.SiLU()
        self.convbn2d_22 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage3_1_main_conv_activate = nn.SiLU()
        self.convbn2d_23 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stage3_1_blocks_0_conv1_activate = nn.SiLU()
        self.convbn2d_24 = nn.Conv2d(bias=True, dilation=(1,1), groups=128, in_channels=128, kernel_size=(5,5), out_channels=128, padding=(2,2), padding_mode='zeros', stride=(1,1))
        self.stage3_1_blocks_0_conv2_depthwise_conv_activate = nn.SiLU()
        self.convbn2d_25 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage3_1_blocks_0_conv2_pointwise_conv_activate = nn.SiLU()
        self.convbn2d_26 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stage3_1_blocks_1_conv1_activate = nn.SiLU()
        self.convbn2d_27 = nn.Conv2d(bias=True, dilation=(1,1), groups=128, in_channels=128, kernel_size=(5,5), out_channels=128, padding=(2,2), padding_mode='zeros', stride=(1,1))
        self.stage3_1_blocks_1_conv2_depthwise_conv_activate = nn.SiLU()
        self.convbn2d_28 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage3_1_blocks_1_conv2_pointwise_conv_activate = nn.SiLU()
        self.stage3_1_attention_global_avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))
        self.stage3_1_attention_fc = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage3_1_attention_act = nn.Hardsigmoid()
        self.convbn2d_29 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage3_1_final_conv_activate = nn.SiLU()
        self.convbn2d_30 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(3,3), out_channels=512, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.stage4_0_activate = nn.SiLU()
        self.convbn2d_31 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_1_conv1_activate = nn.SiLU()
        self.stage4_1_poolings_0 = nn.MaxPool2d(ceil_mode=False, dilation=(1,1), kernel_size=(5,5), padding=(2,2), return_indices=False, stride=(1,1))
        self.stage4_1_poolings_1 = nn.MaxPool2d(ceil_mode=False, dilation=(1,1), kernel_size=(9,9), padding=(4,4), return_indices=False, stride=(1,1))
        self.stage4_1_poolings_2 = nn.MaxPool2d(ceil_mode=False, dilation=(1,1), kernel_size=(13,13), padding=(6,6), return_indices=False, stride=(1,1))
        self.convbn2d_32 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=1024, kernel_size=(1,1), out_channels=512, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_1_conv2_activate = nn.SiLU()
        self.convbn2d_33 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_2_short_conv_activate = nn.SiLU()
        self.convbn2d_34 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_2_main_conv_activate = nn.SiLU()
        self.convbn2d_35 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(3,3), out_channels=256, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.stage4_2_blocks_0_conv1_activate = nn.SiLU()
        self.convbn2d_36 = nn.Conv2d(bias=True, dilation=(1,1), groups=256, in_channels=256, kernel_size=(5,5), out_channels=256, padding=(2,2), padding_mode='zeros', stride=(1,1))
        self.stage4_2_blocks_0_conv2_depthwise_conv_activate = nn.SiLU()
        self.convbn2d_37 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=256, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_2_blocks_0_conv2_pointwise_conv_activate = nn.SiLU()
        self.stage4_2_attention_global_avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))
        self.stage4_2_attention_fc = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=512, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_2_attention_act = nn.Hardsigmoid()
        self.convbn2d_38 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=512, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.stage4_2_final_conv_activate = nn.SiLU()
        self.head_final_layer = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=512, kernel_size=(1,1), out_channels=4, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.head_mlp_1 = nn.Linear(bias=False, in_features=49, out_features=256)
        self.head_gau_uv = nn.Linear(bias=False, in_features=256, out_features=1152)
        self.head_gau_act_fn = nn.ReLU()
        self.head_gau_o = nn.Linear(bias=False, in_features=512, out_features=256)
        self.head_cls_x = nn.Linear(bias=False, in_features=256, out_features=448)
        self.head_cls_y = nn.Linear(bias=False, in_features=256, out_features=448)

        archive = zipfile.ZipFile('rtmpose.pnnx.bin', 'r')
        self.convbn2d_0.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_0.bias', (16), 'float32')
        self.convbn2d_0.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_0.weight', (16,3,3,3), 'float32')
        self.convbn2d_1.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_1.bias', (16), 'float32')
        self.convbn2d_1.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_1.weight', (16,16,3,3), 'float32')
        self.convbn2d_2.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_2.bias', (32), 'float32')
        self.convbn2d_2.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_2.weight', (32,16,3,3), 'float32')
        self.convbn2d_3.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_3.bias', (64), 'float32')
        self.convbn2d_3.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_3.weight', (64,32,3,3), 'float32')
        self.convbn2d_4.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_4.bias', (32), 'float32')
        self.convbn2d_4.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_4.weight', (32,64,1,1), 'float32')
        self.convbn2d_5.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_5.bias', (32), 'float32')
        self.convbn2d_5.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_5.weight', (32,64,1,1), 'float32')
        self.convbn2d_6.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_6.bias', (32), 'float32')
        self.convbn2d_6.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_6.weight', (32,32,3,3), 'float32')
        self.convbn2d_7.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_7.bias', (32), 'float32')
        self.convbn2d_7.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_7.weight', (32,1,5,5), 'float32')
        self.convbn2d_8.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_8.bias', (32), 'float32')
        self.convbn2d_8.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_8.weight', (32,32,1,1), 'float32')
        self.stage1_1_attention_fc.bias = self.load_pnnx_bin_as_parameter(archive, 'stage1.1.attention.fc.bias', (64), 'float32')
        self.stage1_1_attention_fc.weight = self.load_pnnx_bin_as_parameter(archive, 'stage1.1.attention.fc.weight', (64,64,1,1), 'float32')
        self.convbn2d_9.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_9.bias', (64), 'float32')
        self.convbn2d_9.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_9.weight', (64,64,1,1), 'float32')
        self.convbn2d_10.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_10.bias', (128), 'float32')
        self.convbn2d_10.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_10.weight', (128,64,3,3), 'float32')
        self.convbn2d_11.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_11.bias', (64), 'float32')
        self.convbn2d_11.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_11.weight', (64,128,1,1), 'float32')
        self.convbn2d_12.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_12.bias', (64), 'float32')
        self.convbn2d_12.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_12.weight', (64,128,1,1), 'float32')
        self.convbn2d_13.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_13.bias', (64), 'float32')
        self.convbn2d_13.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_13.weight', (64,64,3,3), 'float32')
        self.convbn2d_14.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_14.bias', (64), 'float32')
        self.convbn2d_14.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_14.weight', (64,1,5,5), 'float32')
        self.convbn2d_15.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_15.bias', (64), 'float32')
        self.convbn2d_15.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_15.weight', (64,64,1,1), 'float32')
        self.convbn2d_16.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_16.bias', (64), 'float32')
        self.convbn2d_16.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_16.weight', (64,64,3,3), 'float32')
        self.convbn2d_17.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_17.bias', (64), 'float32')
        self.convbn2d_17.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_17.weight', (64,1,5,5), 'float32')
        self.convbn2d_18.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_18.bias', (64), 'float32')
        self.convbn2d_18.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_18.weight', (64,64,1,1), 'float32')
        self.stage2_1_attention_fc.bias = self.load_pnnx_bin_as_parameter(archive, 'stage2.1.attention.fc.bias', (128), 'float32')
        self.stage2_1_attention_fc.weight = self.load_pnnx_bin_as_parameter(archive, 'stage2.1.attention.fc.weight', (128,128,1,1), 'float32')
        self.convbn2d_19.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_19.bias', (128), 'float32')
        self.convbn2d_19.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_19.weight', (128,128,1,1), 'float32')
        self.convbn2d_20.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_20.bias', (256), 'float32')
        self.convbn2d_20.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_20.weight', (256,128,3,3), 'float32')
        self.convbn2d_21.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_21.bias', (128), 'float32')
        self.convbn2d_21.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_21.weight', (128,256,1,1), 'float32')
        self.convbn2d_22.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_22.bias', (128), 'float32')
        self.convbn2d_22.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_22.weight', (128,256,1,1), 'float32')
        self.convbn2d_23.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_23.bias', (128), 'float32')
        self.convbn2d_23.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_23.weight', (128,128,3,3), 'float32')
        self.convbn2d_24.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_24.bias', (128), 'float32')
        self.convbn2d_24.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_24.weight', (128,1,5,5), 'float32')
        self.convbn2d_25.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_25.bias', (128), 'float32')
        self.convbn2d_25.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_25.weight', (128,128,1,1), 'float32')
        self.convbn2d_26.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_26.bias', (128), 'float32')
        self.convbn2d_26.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_26.weight', (128,128,3,3), 'float32')
        self.convbn2d_27.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_27.bias', (128), 'float32')
        self.convbn2d_27.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_27.weight', (128,1,5,5), 'float32')
        self.convbn2d_28.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_28.bias', (128), 'float32')
        self.convbn2d_28.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_28.weight', (128,128,1,1), 'float32')
        self.stage3_1_attention_fc.bias = self.load_pnnx_bin_as_parameter(archive, 'stage3.1.attention.fc.bias', (256), 'float32')
        self.stage3_1_attention_fc.weight = self.load_pnnx_bin_as_parameter(archive, 'stage3.1.attention.fc.weight', (256,256,1,1), 'float32')
        self.convbn2d_29.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_29.bias', (256), 'float32')
        self.convbn2d_29.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_29.weight', (256,256,1,1), 'float32')
        self.convbn2d_30.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_30.bias', (512), 'float32')
        self.convbn2d_30.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_30.weight', (512,256,3,3), 'float32')
        self.convbn2d_31.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_31.bias', (256), 'float32')
        self.convbn2d_31.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_31.weight', (256,512,1,1), 'float32')
        self.convbn2d_32.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_32.bias', (512), 'float32')
        self.convbn2d_32.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_32.weight', (512,1024,1,1), 'float32')
        self.convbn2d_33.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_33.bias', (256), 'float32')
        self.convbn2d_33.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_33.weight', (256,512,1,1), 'float32')
        self.convbn2d_34.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_34.bias', (256), 'float32')
        self.convbn2d_34.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_34.weight', (256,512,1,1), 'float32')
        self.convbn2d_35.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_35.bias', (256), 'float32')
        self.convbn2d_35.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_35.weight', (256,256,3,3), 'float32')
        self.convbn2d_36.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_36.bias', (256), 'float32')
        self.convbn2d_36.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_36.weight', (256,1,5,5), 'float32')
        self.convbn2d_37.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_37.bias', (256), 'float32')
        self.convbn2d_37.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_37.weight', (256,256,1,1), 'float32')
        self.stage4_2_attention_fc.bias = self.load_pnnx_bin_as_parameter(archive, 'stage4.2.attention.fc.bias', (512), 'float32')
        self.stage4_2_attention_fc.weight = self.load_pnnx_bin_as_parameter(archive, 'stage4.2.attention.fc.weight', (512,512,1,1), 'float32')
        self.convbn2d_38.bias = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_38.bias', (512), 'float32')
        self.convbn2d_38.weight = self.load_pnnx_bin_as_parameter(archive, 'convbn2d_38.weight', (512,512,1,1), 'float32')
        self.head_final_layer.bias = self.load_pnnx_bin_as_parameter(archive, 'head.final_layer.bias', (4), 'float32')
        self.head_final_layer.weight = self.load_pnnx_bin_as_parameter(archive, 'head.final_layer.weight', (4,512,1,1), 'float32')
        self.head_mlp_1.weight = self.load_pnnx_bin_as_parameter(archive, 'head.mlp.1.weight', (256,49), 'float32')
        self.head_gau_uv.weight = self.load_pnnx_bin_as_parameter(archive, 'head.gau.uv.weight', (1152,256), 'float32')
        self.head_gau_o.weight = self.load_pnnx_bin_as_parameter(archive, 'head.gau.o.weight', (256,512), 'float32')
        self.head_cls_x.weight = self.load_pnnx_bin_as_parameter(archive, 'head.cls_x.weight', (448,256), 'float32')
        self.head_cls_y.weight = self.load_pnnx_bin_as_parameter(archive, 'head.cls_y.weight', (448,256), 'float32')
        self.head_gau_data = self.load_pnnx_bin_as_parameter(archive, 'head.gau.data', (2,128), 'float32')
        self.pnnx_fold_465_data = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_465.data', (1,1,2,128), 'float32')
        self.head_gau_res_scale_data = self.load_pnnx_bin_as_parameter(archive, 'head.gau.res_scale.data', (256), 'float32')
        archive.close()

    def load_pnnx_bin_as_parameter(self, archive, key, shape, dtype, requires_grad=True):
        return nn.Parameter(self.load_pnnx_bin_as_tensor(archive, key, shape, dtype), requires_grad)

    def load_pnnx_bin_as_tensor(self, archive, key, shape, dtype):
        fd, tmppath = tempfile.mkstemp()
        with os.fdopen(fd, 'wb') as tmpf, archive.open(key) as keyfile:
            tmpf.write(keyfile.read())
        m = np.memmap(tmppath, dtype=dtype, mode='r', shape=shape).copy()
        os.remove(tmppath)
        return torch.from_numpy(m)

    def forward(self, v_0):
        v_1 = self.convbn2d_0(v_0)
        v_2 = self.stem_0_activate(v_1)
        v_3 = self.convbn2d_1(v_2)
        v_4 = self.stem_1_activate(v_3)
        v_5 = self.convbn2d_2(v_4)
        v_6 = self.stem_2_activate(v_5)
        v_7 = self.convbn2d_3(v_6)
        v_8 = self.stage1_0_activate(v_7)
        v_9 = self.convbn2d_4(v_8)
        v_10 = self.stage1_1_short_conv_activate(v_9)
        v_11 = self.convbn2d_5(v_8)
        v_12 = self.stage1_1_main_conv_activate(v_11)
        v_13 = self.convbn2d_6(v_12)
        v_14 = self.stage1_1_blocks_0_conv1_activate(v_13)
        v_15 = self.convbn2d_7(v_14)
        v_16 = self.stage1_1_blocks_0_conv2_depthwise_conv_activate(v_15)
        v_17 = self.convbn2d_8(v_16)
        v_18 = self.stage1_1_blocks_0_conv2_pointwise_conv_activate(v_17)
        v_19 = (v_18 + v_12)
        v_20 = torch.cat((v_19, v_10), dim=1)
        v_21 = self.stage1_1_attention_global_avgpool(v_20)
        v_22 = self.stage1_1_attention_fc(v_21)
        v_23 = self.stage1_1_attention_act(v_22)
        v_24 = (v_20 * v_23)
        v_25 = self.convbn2d_9(v_24)
        v_26 = self.stage1_1_final_conv_activate(v_25)
        v_27 = self.convbn2d_10(v_26)
        v_28 = self.stage2_0_activate(v_27)
        v_29 = self.convbn2d_11(v_28)
        v_30 = self.stage2_1_short_conv_activate(v_29)
        v_31 = self.convbn2d_12(v_28)
        v_32 = self.stage2_1_main_conv_activate(v_31)
        v_33 = self.convbn2d_13(v_32)
        v_34 = self.stage2_1_blocks_0_conv1_activate(v_33)
        v_35 = self.convbn2d_14(v_34)
        v_36 = self.stage2_1_blocks_0_conv2_depthwise_conv_activate(v_35)
        v_37 = self.convbn2d_15(v_36)
        v_38 = self.stage2_1_blocks_0_conv2_pointwise_conv_activate(v_37)
        v_39 = (v_38 + v_32)
        v_40 = self.convbn2d_16(v_39)
        v_41 = self.stage2_1_blocks_1_conv1_activate(v_40)
        v_42 = self.convbn2d_17(v_41)
        v_43 = self.stage2_1_blocks_1_conv2_depthwise_conv_activate(v_42)
        v_44 = self.convbn2d_18(v_43)
        v_45 = self.stage2_1_blocks_1_conv2_pointwise_conv_activate(v_44)
        v_46 = (v_45 + v_39)
        v_47 = torch.cat((v_46, v_30), dim=1)
        v_48 = self.stage2_1_attention_global_avgpool(v_47)
        v_49 = self.stage2_1_attention_fc(v_48)
        v_50 = self.stage2_1_attention_act(v_49)
        v_51 = (v_47 * v_50)
        v_52 = self.convbn2d_19(v_51)
        v_53 = self.stage2_1_final_conv_activate(v_52)
        v_54 = self.convbn2d_20(v_53)
        v_55 = self.stage3_0_activate(v_54)
        v_56 = self.convbn2d_21(v_55)
        v_57 = self.stage3_1_short_conv_activate(v_56)
        v_58 = self.convbn2d_22(v_55)
        v_59 = self.stage3_1_main_conv_activate(v_58)
        v_60 = self.convbn2d_23(v_59)
        v_61 = self.stage3_1_blocks_0_conv1_activate(v_60)
        v_62 = self.convbn2d_24(v_61)
        v_63 = self.stage3_1_blocks_0_conv2_depthwise_conv_activate(v_62)
        v_64 = self.convbn2d_25(v_63)
        v_65 = self.stage3_1_blocks_0_conv2_pointwise_conv_activate(v_64)
        v_66 = (v_65 + v_59)
        v_67 = self.convbn2d_26(v_66)
        v_68 = self.stage3_1_blocks_1_conv1_activate(v_67)
        v_69 = self.convbn2d_27(v_68)
        v_70 = self.stage3_1_blocks_1_conv2_depthwise_conv_activate(v_69)
        v_71 = self.convbn2d_28(v_70)
        v_72 = self.stage3_1_blocks_1_conv2_pointwise_conv_activate(v_71)
        v_73 = (v_72 + v_66)
        v_74 = torch.cat((v_73, v_57), dim=1)
        v_75 = self.stage3_1_attention_global_avgpool(v_74)
        v_76 = self.stage3_1_attention_fc(v_75)
        v_77 = self.stage3_1_attention_act(v_76)
        v_78 = (v_74 * v_77)
        v_79 = self.convbn2d_29(v_78)
        v_80 = self.stage3_1_final_conv_activate(v_79)
        v_81 = self.convbn2d_30(v_80)
        v_82 = self.stage4_0_activate(v_81)
        v_83 = self.convbn2d_31(v_82)
        v_84 = self.stage4_1_conv1_activate(v_83)
        v_85 = self.stage4_1_poolings_0(v_84)
        v_86 = self.stage4_1_poolings_1(v_84)
        v_87 = self.stage4_1_poolings_2(v_84)
        v_88 = torch.cat((v_84, v_85, v_86, v_87), dim=1)
        v_89 = self.convbn2d_32(v_88)
        v_90 = self.stage4_1_conv2_activate(v_89)
        v_91 = self.convbn2d_33(v_90)
        v_92 = self.stage4_2_short_conv_activate(v_91)
        v_93 = self.convbn2d_34(v_90)
        v_94 = self.stage4_2_main_conv_activate(v_93)
        v_95 = self.convbn2d_35(v_94)
        v_96 = self.stage4_2_blocks_0_conv1_activate(v_95)
        v_97 = self.convbn2d_36(v_96)
        v_98 = self.stage4_2_blocks_0_conv2_depthwise_conv_activate(v_97)
        v_99 = self.convbn2d_37(v_98)
        v_100 = self.stage4_2_blocks_0_conv2_pointwise_conv_activate(v_99)
        v_101 = torch.cat((v_100, v_92), dim=1)
        v_102 = self.stage4_2_attention_global_avgpool(v_101)
        v_103 = self.stage4_2_attention_fc(v_102)
        v_104 = self.stage4_2_attention_act(v_103)
        v_105 = (v_101 * v_104)
        v_106 = self.convbn2d_38(v_105)
        v_107 = self.stage4_2_final_conv_activate(v_106)
        v_108 = self.head_final_layer(v_107)
        v_109 = torch.flatten(input=v_108, end_dim=-1, start_dim=2)
        v_110 = torch.norm(input=v_109, dim=(-1,), keepdim=True, p='fro')
        v_111 = (v_110 * 1.428571e-01)
        v_112 = torch.clamp(input=v_111, max=None, min=0.000010)
        v_113 = ((v_109 / v_112) * 1.962991e-01)
        v_114 = self.head_mlp_1(v_113)
        v_115 = self.head_gau_data
        v_116 = torch.norm(input=v_114, dim=(-1,), keepdim=True, p='fro')
        v_117 = (v_116 * 6.250000e-02)
        v_118 = torch.clamp(input=v_117, max=None, min=0.000010)
        v_119 = ((v_114 / v_118) * 7.136216e-01)
        v_120 = self.head_gau_uv(v_119)
        v_121 = self.head_gau_act_fn(v_120)
        v_122, v_123, v_124 = torch.split(tensor=v_121, dim=2, split_size_or_sections=(512,512,128))
        v_125 = self.pnnx_fold_465_data
        v_126 = torch.unsqueeze(input=v_124, dim=2)
        v_127 = ((v_126 * v_125) + v_115)
        v_128, v_129 = torch.unbind(input=v_127, dim=2)
        v_130 = torch.permute(input=v_129, dims=(0,2,1))
        v_131 = torch.bmm(input=v_128, mat2=v_130)
        v_132 = (v_131 / 1.131371e+01)
        v_133 = F.relu(input=v_132)
        v_134 = torch.square(v_133)
        v_135 = torch.bmm(input=v_134, mat2=v_123)
        v_136 = (v_122 * v_135)
        v_137 = self.head_gau_o(v_136)
        v_138 = self.head_gau_res_scale_data
        v_139 = ((v_114 * v_138) + v_137)
        v_140 = self.head_cls_x(v_139)
        v_141 = self.head_cls_y(v_139)
        v_142 = (v_140, v_141, )
        return v_142

def export_torchscript():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 224, 224, dtype=torch.float)

    mod = torch.jit.trace(net, v_0)
    mod.save("rtmpose_pnnx.py.pt")

def export_onnx():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 224, 224, dtype=torch.float)

    torch.onnx._export(net, v_0, "rtmpose_pnnx.py.onnx", export_params=True, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK, opset_version=13, input_names=['in0'], output_names=['out0'])

def test_inference():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 224, 224, dtype=torch.float)

    return net(v_0)

if __name__ == "__main__":
    print(test_inference())
